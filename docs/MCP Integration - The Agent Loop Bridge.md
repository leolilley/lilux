# MCP Integration: The Agent Loop Bridge

## The Revelation from Amp's Agent Loop

As revealed in [Thorsten Ball's "How to Build an Agent"](https://ampcode.com/how-to-build-an-agent), the core of an agent is shockingly simple:

> **"It's an LLM, a loop, and enough tokens."**

Here's the actual loop (adapted from Amp's code):

```go
for {
    userInput = getUserMessage()
    conversation.append(userInput)

    response = runInference(conversation)
    conversation.append(response)

    for content in response.Content {
        if content.Type == "tool_use" {
            result = executeTool(content)
            conversation.append(result)

            // Continue inference with tool result
            response = runInference(conversation)
        } else {
            print(content.Text)
        }
    }
}
```

**That's it.** The "secret" is that there is no secret. It's:

1. Maintain conversation history
2. Send to model
3. If model outputs tool use â†’ execute tool â†’ add result â†’ loop back
4. If model outputs text â†’ display â†’ get next user input

## The MCP Reality Check

Traditional MCP (Model Context Protocol) already has this figured out:

- **MCP Servers** expose tools with JSON schemas
- **MCP Clients** (like Claude Desktop, Cursor) send those schemas to the model
- **Models** generate tool calls in JSON format
- **Clients** execute tools via MCP protocol
- **Results** get added to conversation

The architecture:

```
User â†’ Claude Desktop (MCP Client)
            â†“
      Loads MCP Servers
            â†“
      Sends tool schemas to Claude API
            â†“
      Claude generates: {"name": "search", "arguments": {...}}
            â†“
      Client executes via MCP protocol
            â†“
      Result â†’ Conversation â†’ Loop
```

**This works.** But it has issues:

- Models see ALL tool schemas (context bloat)
- Tool schemas expose implementation details to cloud
- Tool calling requires specific API support
- Can't easily swap or fine-tune the routing layer

## The Intent Marker Innovation

Our MCP 2.0 / Intent Marker approach flips this:

```
User â†’ Frontend Model
            â†“
      "[TOOL: search for email scripts]"
            â†“
      Harness intercepts marker
            â†“
      FunctionGemma routes: search(item_type="script", query="email")
            â†“
      Execute via Kiwi MCP
            â†“
      Result â†’ Conversation â†’ Loop
```

Benefits:

- Model only knows `[TOOL: intent]` syntax - no schemas
- Routing happens locally with FunctionGemma
- Privacy-preserving
- Works with ANY model (even ones without tool calling APIs)

But we're **reinventing the wheel**. MCP servers already exist. Kiwi MCP already exists. How do we **bridge** these approaches?

---

## The Bridge: Using MCP Infrastructure with Intent Routing

The solution: **Use MCP's infrastructure, swap out the routing layer.**

We're NOT creating a new protocol. We're using:

- âœ… MCP's stdio/SSE server protocol
- âœ… MCP's tool schema format
- âœ… MCP's client-server communication
- âœ… MCP's tool execution

We're ONLY replacing:

- âŒ "Model sees schemas and generates JSON tool calls"

With:

- âœ… "Model outputs `[TOOL: intent]` â†’ FunctionGemma routes â†’ Execute via MCP"

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INPUT                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONVERSATIONAL MODEL                          â”‚
â”‚                                                                  â”‚
â”‚  Trained to output:                                              â”‚
â”‚  â€¢ [TOOL: natural language intent]                               â”‚
â”‚  â€¢ Plain text conversation                                       â”‚
â”‚                                                                  â”‚
â”‚  Does NOT see MCP schemas                                        â”‚
â”‚  Does NOT know about JSON tool calling                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTENT ROUTING HARNESS                        â”‚
â”‚                                                                  â”‚
â”‚  1. Intercepts [TOOL: ...] markers                               â”‚
â”‚  2. Routes to FunctionGemma                                      â”‚
â”‚  3. Gets tool call JSON                                          â”‚
â”‚  4. Executes via MCP protocol                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FUNCTIONGEMMA ROUTER (270M)               â”‚
â”‚                                                        â”‚
â”‚  Input: "search for email scripts"                    â”‚
â”‚  Output: {"name": "search",                           â”‚
â”‚           "arguments": {"item_type": "script",        â”‚
â”‚                         "query": "email"}}            â”‚
â”‚                                                        â”‚
â”‚  Knows ONLY 3 primitives:                             â”‚
â”‚  - search(item_type, query)                           â”‚
â”‚  - load(item_type, item_id)                           â”‚
â”‚  - execute(directive_name, params)                    â”‚
â”‚                                                        â”‚
â”‚  Context cache: Predicted directives                  â”‚
â”‚  (NOT MCP tool schemas!)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      KIWI MCP CLIENT                             â”‚
â”‚                                                                  â”‚
â”‚  Standard MCP protocol:                                          â”‚
â”‚  â€¢ search/load/execute primitives                                â”‚
â”‚  â€¢ Returns directive                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND LLM (Per Directive)                    â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Reads directive XML                                           â”‚
â”‚  â€¢ Knows ALL MCP tool schemas (git, file, db, etc.)              â”‚
â”‚  â€¢ Executes directive steps using MCP tools                      â”‚
â”‚  â€¢ Model tier specified by directive                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key point:** FunctionGemma routes to directives, not to MCP tools directly. The directive itself (executed by backend LLM) contains MCP tool knowledge.

---

## Implementation: Intent Routing with MCP Infrastructure

```python
# intent_routing_mcp_harness.py

import re
import asyncio
from typing import AsyncIterator, Dict, List, Any
from mcp import Client as MCPClient, StdioServerParameters
from mcp.types import Tool, CallToolResult

class IntentRoutingMCPHarness:
    """
    Agent harness that uses MCP infrastructure with intent marker routing.

    Architecture:
    - Model outputs [TOOL: natural language intent]
    - FunctionGemma routes intent â†’ MCP tool call
    - Execute via standard MCP protocol
    - MCP servers unchanged
    """

    def __init__(self, router_model_path: str):
        # Standard MCP client (same as Claude Desktop uses)
        self.mcp_client = MCPClient("intent-routing-agent")

        # FunctionGemma router (our innovation)
        self.router = FunctionGemmaRouter(router_model_path)

        # Track connected MCP servers
        self.mcp_servers = {}
        self.available_tools = {}

        # Conversation history (Amp-style loop)
        self.conversation = []

    async def connect_mcp_server(
        self,
        server_name: str,
        command: str,
        args: List[str]
    ):
        """
        Connect to an MCP server using STANDARD MCP protocol.

        This is EXACTLY how Claude Desktop connects to MCP servers.
        We're using the same infrastructure, same protocols.
        """

        # Standard MCP stdio connection
        server_params = StdioServerParameters(
            command=command,
            args=args
        )

        # Connect via standard MCP protocol (no changes to protocol)
        await self.mcp_client.connect_to_server(server_params)

        self.mcp_servers[server_name] = {
            "command": command,
            "args": args
        }

        # Get available tools from server (standard MCP call)
        tools_response = await self.mcp_client.list_tools()

        # Store tool schemas for FunctionGemma training/routing
        for tool in tools_response.tools:
            self.available_tools[tool.name] = {
                "server": server_name,
                "schema": tool
            }

        print(f"âœ“ Connected to MCP server '{server_name}' ({len(tools_response.tools)} tools)")

        # FunctionGemma doesn't need to register these schemas
        # It only knows search/load/execute primitives
        # The directives themselves will use these MCP tools

    async def chat(
        self,
        user_message: str,
        model_client: Any,  # Your frontend model (Phi-3, Gemma, etc.)
        system_prompt: Optional[str] = None
    ) -> AsyncIterator[str]:
        """
        The Amp-style agent loop with intent marker routing.

        Loop:
        1. Add user message to conversation
        2. Stream model response
        3. Detect [TOOL: ...] markers
        4. Route through FunctionGemma
        5. Execute via MCP protocol (unchanged)
        6. Add result to conversation
        7. Continue inference

        This is the SAME loop as traditional MCP, we just changed
        step 4 (routing) from "model generates JSON" to "FunctionGemma routes".
        """

        # Add user message
        self.conversation.append({
            "role": "user",
            "content": user_message
        })

        # Build system prompt (only teaches intent marker syntax)
        full_system_prompt = self._build_system_prompt(system_prompt)

        # The Amp loop
        buffer = ""

        async for chunk in model_client.stream(
            messages=self.conversation,
            system=full_system_prompt
        ):
            buffer += chunk

            # Check for intent markers
            marker_match = re.search(r'\[TOOL:\s*([^\]]+)\]', buffer)

            if marker_match:
                intent = marker_match.group(1).strip()

                # Yield text before marker
                yield buffer[:marker_match.start()]

                # Route through FunctionGemma
                # This is our ONLY change from traditional MCP
                yield "\nğŸ”§ "
                tool_call = await self.router.predict(intent)

                # Execute via STANDARD MCP protocol
                # This is exactly how traditional MCP works
                result = await self._execute_mcp_tool(
                    tool_call["name"],
                    tool_call["arguments"]
                )
                yield "âœ“\n"

                # Add tool result to conversation
                result_text = f"[RESULT: {tool_call['name']} | {self._summarize(result)}]"
                self.conversation.append({
                    "role": "assistant",
                    "content": buffer[:marker_match.start()] + result_text
                })

                # Continue inference with result (Amp-style loop)
                buffer = ""
                async for chunk in model_client.stream(
                    messages=self.conversation,
                    system=full_system_prompt
                ):
                    buffer += chunk
                    yield chunk

                break

            yield chunk

        # Add final response to conversation
        self.conversation.append({
            "role": "assistant",
            "content": buffer
        })

    async def _execute_mcp_tool(
        self,
        tool_name: str,
        arguments: Dict[str, Any]
    ) -> Any:
        """Execute tool via MCP protocol"""

        if tool_name not in self.available_tools:
            raise ValueError(f"Tool '{tool_name}' not available")

        tool_info = self.available_tools[tool_name]

        # Call tool via MCP
        result = await self.mcp_client.call_tool(
            name=tool_name,
            arguments=arguments
        )

        return result

    def _build_system_prompt(self, custom_prompt: Optional[str] = None) -> str:
        """
        Build system prompt for intent marker routing.

        IMPORTANT: We do NOT show MCP tool schemas to the model.
        That's the whole point - the model doesn't need to know implementation details.
        FunctionGemma handles all that.
        """

        base_prompt = custom_prompt or "You are a helpful assistant."

        # Only teach intent marker syntax (minimal prompt)
        base_prompt += """

# TOOL PROTOCOL

When you need to use tools, output:
[TOOL: natural language description of what you want]

Examples:
- [TOOL: search for email scripts]
- [TOOL: read the config file]
- [TOOL: create a new parser function]
- [TOOL: run the sync directive]

The system will automatically understand and execute your intent.
You don't need to know tool names, parameters, or schemas.
Just describe what you want naturally.
"""

        return base_prompt

    def _summarize(self, result: Any) -> str:
        """Create brief summary of tool result"""

        if isinstance(result, CallToolResult):
            if result.content:
                # Extract text from content blocks
                texts = [c.text for c in result.content if hasattr(c, 'text')]
                combined = " ".join(texts)
                return combined[:100] + "..." if len(combined) > 100 else combined
            return "Success"

        return str(result)[:100]
```

---

## Usage Example

### Connecting to MCP Servers and Using Intent Routing

```python
# intent_routing_agent.py

async def main():
    """
    Use MCP infrastructure with intent marker routing.
    Same servers, same protocols - just different routing.
    """

    # Initialize harness with FunctionGemma router
    harness = IntentRoutingMCPHarness(
        router_model_path="universal-mcp-router.gguf"
    )

    # Connect to MCP servers using STANDARD MCP protocol
    # These are the EXACT SAME servers that Claude Desktop would use

    # Kiwi MCP server
    await harness.connect_mcp_server(
        server_name="kiwi",
        command="python",
        args=["-m", "kiwi_mcp.server"]
    )

    # Filesystem MCP server (from MCP ecosystem)
    await harness.connect_mcp_server(
        server_name="filesystem",
        command="npx",
        args=["-y", "@modelcontextprotocol/server-filesystem", "/home/user/project"]
    )

    # Git MCP server (from MCP ecosystem)
    await harness.connect_mcp_server(
        server_name="git",
        command="npx",
        args=["-y", "@modelcontextprotocol/server-git"]
    )

    # Use a small frontend model (Phi-3, Gemma, etc.)
    # No need for expensive cloud model with tool calling support
    frontend = LocalLlama("phi-3-mini.gguf")

    # Chat with user
    print("Agent ready. Connected to 3 MCP servers.")

    async for chunk in harness.chat(
        user_message="Search for email scripts and show me the first one",
        model_client=frontend
    ):
        print(chunk, end="", flush=True)

# Output:
# I'll search for those! ğŸ”§ âœ“
# Found 3 email scripts:
# â€¢ email_enricher.py
# â€¢ email_validator.py
# â€¢ email_sender.py
#
# Let me show you the first one: ğŸ”§ âœ“
# [File contents displayed...]

# Behind the scenes:
# 1. Frontend: [TOOL: search for email scripts]
# 2. FunctionGemma: search(item_type="script", query="email")
# 3. MCP Client: calls Kiwi MCP server via stdio
# 4. Result flows back
# 5. Frontend: [TOOL: read file email_enricher.py]
# 6. FunctionGemma: read_file(path="/home/user/project/email_enricher.py")
# 7. MCP Client: calls filesystem MCP server
# 8. Result flows back
```

### Configuration File (MCP-Compatible)

You can even use the SAME config format as MCP:

```json
{
  "mcpServers": {
    "kiwi": {
      "command": "python",
      "args": ["-m", "kiwi_mcp.server"]
    },
    "filesystem": {
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-filesystem",
        "/home/user/project"
      ]
    },
    "git": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-git"]
    }
  }
}
```

```python
# Load from standard MCP config
import json

with open("mcp_config.json") as f:
    config = json.load(f)

harness = IntentRoutingMCPHarness("universal-mcp-router.gguf")

for server_name, server_config in config["mcpServers"].items():
    await harness.connect_mcp_server(
        server_name=server_name,
        command=server_config["command"],
        args=server_config["args"]
    )
```

---

## Training FunctionGemma on MCP Schemas

> **Note on Lilux Architecture**: In the full Lilux system, FunctionGemma only trains on the 3 primitives (search/load/execute) and routes to directives. The directives themselves contain MCP tool knowledge. This section describes a more general approach where FunctionGemma routes directly to MCP tools, which may be useful for simpler systems or prototyping.

The general bridge approach requires training FunctionGemma to understand MCP tool schemas:

```python
# train_router_on_mcp.py

def generate_training_data_from_mcp_server(server_params: Dict) -> List[Dict]:
    """
    Connect to MCP server and generate training data from its tool schemas.
    """

    # Connect to server
    client = MCPClient("training-data-generator")
    await client.connect_to_server(server_params)

    # Get tools
    tools_response = await client.list_tools()

    training_data = []

    for tool in tools_response.tools:
        # Generate natural language variations for this tool
        variations = generate_intent_variations(
            tool_name=tool.name,
            description=tool.description,
            parameters=tool.inputSchema
        )

        for intent in variations:
            # Create training example
            training_data.append({
                "intent": intent,
                "tool_call": {
                    "name": tool.name,
                    "arguments": extract_params_from_intent(intent, tool.inputSchema)
                }
            })

    return training_data


def generate_intent_variations(tool_name: str, description: str, parameters: Dict) -> List[str]:
    """
    Generate natural language variations for a tool.

    Example for Kiwi MCP's search tool:
    - "search for email scripts"
    - "find scripts about email"
    - "look for email-related scripts"
    - "show me scripts for email"
    """

    variations = []

    # Use Claude to generate variations
    prompt = f"""Generate 10 natural language ways someone might ask to use this tool:

Tool: {tool_name}
Description: {description}
Parameters: {json.dumps(parameters, indent=2)}

Generate diverse phrasings, from casual to formal.
Return as JSON array of strings."""

    response = claude.messages.create(
        model="claude-sonnet-4-20250514",
        messages=[{"role": "user", "content": prompt}]
    )

    variations = json.loads(response.content[0].text)
    return variations


# Complete training pipeline
async def train_router_on_all_mcp_servers():
    """
    Train FunctionGemma on ALL available MCP servers.
    """

    mcp_servers = [
        {"name": "kiwi", "command": "python", "args": ["-m", "kiwi_mcp.server"]},
        {"name": "filesystem", "command": "npx", "args": ["-y", "@modelcontextprotocol/server-filesystem", "/"]},
        {"name": "git", "command": "npx", "args": ["-y", "@modelcontextprotocol/server-git"]},
        # ... add more MCP servers
    ]

    all_training_data = []

    for server in mcp_servers:
        print(f"Generating training data from {server['name']}...")

        data = await generate_training_data_from_mcp_server(
            StdioServerParameters(
                command=server["command"],
                args=server["args"]
            )
        )

        all_training_data.extend(data)

    print(f"Generated {len(all_training_data)} training examples from {len(mcp_servers)} MCP servers")

    # Save for training
    with open("mcp_router_training.jsonl", "w") as f:
        for example in all_training_data:
            f.write(json.dumps(example) + "\n")

    # Train FunctionGemma
    train_function_gemma(
        base_model="google/functiongemma-270m",
        training_data="mcp_router_training.jsonl",
        output_path="universal-mcp-router"
    )
```

---

## The Multi-Net Architecture with MCP

Now let's integrate this with our Multi-Net architecture:

```python
# multinet_with_mcp.py

class MultiNetMCPAgent:
    """
    Multi-Net architecture integrated with MCP ecosystem.
    """

    def __init__(self):
        # The nets
        self.frontend = ConversationalFrontend("phi-3-mini.gguf")  # 3B
        self.router = FunctionGemmaRouter("universal-mcp-router.gguf")  # 270M
        self.reasoner = ReasoningClient()  # Claude or local 70B

        # The MCP bridge
        self.mcp_harness = UniversalMCPHarness(
            router_model_path="universal-mcp-router.gguf",
            enable_intent_markers=True
        )

        # Connect to MCP servers
        self._connect_mcp_servers()

    async def _connect_mcp_servers(self):
        """Connect to all MCP servers"""

        # Kiwi MCP
        await self.mcp_harness.connect_mcp_server(
            "kiwi",
            "python",
            ["-m", "kiwi_mcp.server"]
        )

        # Filesystem
        await self.mcp_harness.connect_mcp_server(
            "filesystem",
            "npx",
            ["-y", "@modelcontextprotocol/server-filesystem", os.getcwd()]
        )

        # Add more MCP servers as needed

    async def chat(self, user_message: str) -> AsyncIterator[str]:
        """
        Multi-net chat with full MCP integration.

        Flow:
        1. Frontend generates response with [TOOL: ...] markers
        2. Harness intercepts markers
        3. Router translates intent â†’ MCP tool call
        4. MCP executes tool
        5. If tool is a directive that needs reasoning, route to reasoner
        6. Results flow back to frontend
        """

        # Add to conversation
        self.mcp_harness.conversation.append({
            "role": "user",
            "content": user_message
        })

        # Stream from frontend
        buffer = ""

        async for token in self.frontend.stream(
            messages=self.mcp_harness.conversation,
            system_prompt=self._build_frontend_prompt()
        ):
            buffer += token

            # Check for intent markers
            marker_match = re.search(r'\[TOOL:\s*([^\]]+)\]', buffer)

            if marker_match:
                intent = marker_match.group(1).strip()

                yield buffer[:marker_match.start()]
                yield "\nğŸ”§ "

                # Route through FunctionGemma
                tool_call = await self.router.predict(intent)

                # Check if this is a Kiwi directive that needs reasoning
                if self._requires_reasoning(tool_call):
                    # Route to reasoner
                    result = await self._execute_with_reasoner(tool_call)
                else:
                    # Execute directly via MCP
                    result = await self.mcp_harness._execute_mcp_tool(
                        tool_call["name"],
                        tool_call["arguments"]
                    )

                yield "âœ“\n"

                # Format result
                result_text = f"[RESULT: {tool_call['name']} | {self._summarize(result)}]"
                buffer = buffer[:marker_match.start()] + result_text

                # Continue frontend with result
                self.mcp_harness.conversation.append({
                    "role": "assistant",
                    "content": buffer
                })

                async for token in self.frontend.stream(
                    messages=self.mcp_harness.conversation,
                    system_prompt=self._build_frontend_prompt()
                ):
                    yield token

                return

            yield token

    def _requires_reasoning(self, tool_call: Dict) -> bool:
        """Check if tool call requires high-reasoning model"""

        # If it's executing a directive, check its model class
        if tool_call["name"] == "execute":
            item_type = tool_call["arguments"].get("item_type")
            item_id = tool_call["arguments"].get("item_id")

            if item_type == "directive":
                # Load directive metadata (lightweight)
                directive = load_directive_metadata(item_id)
                return directive.model_class == "high-reasoning"

        return False

    async def _execute_with_reasoner(self, tool_call: Dict) -> Any:
        """Execute tool call using reasoning engine"""

        # Get directive
        directive = await load_directive(tool_call["arguments"]["item_id"])

        # Execute using reasoner
        return await self.reasoner.execute_directive(directive)
```

---

## The Complete Picture

```
User: "Search for email scripts and refactor the best one"
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FRONTEND (Phi-3 Mini 3B)                    â”‚
â”‚                                                      â”‚
â”‚  "I'll search for those and refactor!               â”‚
â”‚   [TOOL: search for email scripts]"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          UNIVERSAL MCP HARNESS                       â”‚
â”‚                                                      â”‚
â”‚  Detects: [TOOL: search for email scripts]          â”‚
â”‚  Routes to FunctionGemma                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FUNCTIONGEMMA ROUTER (270M)                 â”‚
â”‚                                                      â”‚
â”‚  Intent: "search for email scripts"                 â”‚
â”‚  Output: search(item_type="script", query="email")  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          MCP PROTOCOL                                â”‚
â”‚                                                      â”‚
â”‚  Executes: kiwi_mcp.search(...)                     â”‚
â”‚  Returns: [email_enricher.py, email_validator.py]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
Frontend: "Found 2 scripts! Now refactoring email_enricher.
           [TOOL: run refactor_script on email_enricher]"
                     â”‚
                     â–¼
Router: refactor_script(target="email_enricher.py")
                     â”‚
                     â–¼
MCP: Load directive "refactor_script"
     model_class="high-reasoning" â† NEEDS BIG BRAIN
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          REASONING ENGINE (Claude/70B)               â”‚
â”‚                                                      â”‚
â”‚  Executes directive steps with deep reasoning        â”‚
â”‚  Returns: Refactored code + explanation              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Every layer uses MCP. The innovation is in the routing intelligence.**

---

## Benefits of Intent Routing with MCP Infrastructure

| Aspect                 | Traditional MCP           | Intent Routing MCP            |
| ---------------------- | ------------------------- | ----------------------------- |
| **MCP Compatibility**  | âœ… All servers            | âœ… All servers (unchanged!)   |
| **MCP Protocol**       | âœ… Standard stdio/SSE     | âœ… Standard stdio/SSE         |
| **Server Changes**     | âœ… None needed            | âœ… None needed                |
| **Client Changes**     | Built-in (Claude, Cursor) | Custom harness                |
| **Model Requirements** | Native tool calling API   | Any model                     |
| **Privacy**            | Schemas sent to cloud     | Schemas stay local            |
| **Routing Speed**      | Cloud API (1.5s)          | Local FunctionGemma (40-80ms) |
| **Model Size**         | 70B+ (cloud)              | 3B frontend + 270M router     |
| **Cost**               | $0.15/request             | $0.001/request                |
| **Training**           | None                      | Train router once             |
| **Flexibility**        | Fixed schemas             | Natural language intents      |

**Key Insight:** We're using the SAME MCP infrastructure (servers, protocols, schemas). We just changed the routing layer from "cloud model generates JSON" to "local FunctionGemma routes intent".

---

## What We're Reusing vs. Changing

### âœ… Reusing from MCP (Unchanged)

1. **Server Protocol**

   - stdio communication
   - SSE for network servers
   - JSON-RPC message format

2. **Tool Schemas**

   - Same JSON Schema format
   - Same `list_tools()` API
   - Same `call_tool()` API

3. **Server Implementations**

   - Use existing MCP servers as-is
   - Kiwi MCP server unchanged
   - Filesystem server unchanged
   - Git server unchanged
   - Weather server unchanged
   - ANY MCP server works

4. **Infrastructure**
   - MCP Client library
   - Server connection handling
   - Tool execution logic

### âŒ Changing (Our Innovation)

1. **Routing Layer**

   - Traditional: Cloud model sees schemas â†’ generates JSON
   - Ours: Local FunctionGemma routes intent â†’ generates JSON

2. **Model Interaction**

   - Traditional: Model sees all tool schemas in prompt
   - Ours: Model only knows `[TOOL: intent]` syntax

3. **Privacy**
   - Traditional: Schemas sent to cloud (Anthropic, OpenAI)
   - Ours: Schemas stay local (FunctionGemma)

**That's it!** We're NOT reinventing MCP. We're using 95% of it, just swapping the routing.

## The Lesson from Amp

As Thorsten Ball said: **"It's an LLM, a loop, and enough tokens."**

The secret is there is no secret. The agent loop is:

```python
while True:
    user_input â†’ conversation
    response â† model(conversation)

    if tool_use_detected:
        result â† execute_tool()
        result â†’ conversation
        continue  # Loop back to model
    else:
        display(response)
        break
```

**That's the core.** Whether you use:

- Traditional MCP (model generates JSON)
- Intent routing (FunctionGemma routes)

The **loop is the same**. The **MCP infrastructure is the same**. We just changed HOW we detect tool use and route to tools.

---

## Next Steps

1. **Implement `UniversalMCPHarness`** - Bridge traditional MCP and intent markers
2. **Train router on MCP schemas** - Generate training data from ALL MCP servers
3. **Test hybrid approach** - Same agent, both modes working
4. **Integrate with Multi-Net** - Frontend + Router + MCP + Reasoner
5. **Deploy** - Use with any MCP server ecosystem

---

_Document generated: 2026-01-17_
_Part of the Kiwi Fine-Tune documentation series_
_Related: MCP 2.0, Multi-Net Architecture, Agent Loop_
_Inspired by: [Amp's "How to Build an Agent"](https://ampcode.com/how-to-build-an-agent)_
